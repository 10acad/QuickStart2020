{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrape for influential Twitter handles & tweets of popular #hashtags\n",
    "\n",
    "sites:\n",
    "- [socialbakers](https://www.socialbakers.com/statistics/twitter/profiles)\n",
    "\n",
    "- [google](https://www.google.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from googlesearch import search\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get handles of top influencers in a country from Top to bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(country = 'nigeria',\n",
    "              driver_path = r'/home/patrick/geckodriver', \n",
    "              name_= 'New Lover.', work_email='love.wins@dummy.com',\n",
    "              phone = 12345, job_title = 'Lover',\n",
    "              company = 'Love', pages=50):\n",
    "    \n",
    "    \"\"\"\n",
    "    change default country name in `country param` to your choice country\n",
    "    \n",
    "    website serves only 10 names per page, hence the pages * 10 is the number of handles to be gotten\n",
    "    \n",
    "    but this is no guarrantee that you will get exactly pages * 10 handles.\n",
    "    \n",
    "    This script assumes the following to work:\n",
    "    \n",
    "    1. You have a vpn on if your ip is not supported by socialbakers.com\n",
    "    \n",
    "    2. You are strictly looking to filter the top influencers by your specified country\n",
    "    \n",
    "        The tag and class_name used are for this purpose.\n",
    "        \n",
    "        You can however modify it, to implement your own version\n",
    "    \n",
    "    3. You have selenium installed ...\n",
    "    \n",
    "    \n",
    "    Change your driver path to the path where it was downloaded on your machine\n",
    "    If you are using chrome, change Firefox to Chrome\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url =f'https://www.socialbakers.com/statistics/twitter/profiles/{country}/'\n",
    "    count = 0\n",
    "    names = []\n",
    "    \n",
    "    driver = webdriver.Firefox(executable_path=driver_path)\n",
    "    \n",
    "    driver.get(base_url)\n",
    "    sleep(15)  \n",
    "    \n",
    "    table = driver.find_elements_by_class_name('acc-placeholder-img') \n",
    "    index =len(table)\n",
    "    \n",
    "    print(f\"@ page {count+1}\")\n",
    "    for row in table:\n",
    "            name = row.text.split(' ')[-1]\n",
    "            if '@' in name:\n",
    "                names.append(name.lstrip('(').rstrip(')'))\n",
    "                \n",
    "    # utility functions\n",
    "    def next_page():\n",
    "        try:\n",
    "            next_btn_class = driver.find_elements_by_class_name('more-center-link')[0]\n",
    "            next_btn = next_btn_class.find_elements_by_tag_name('a')\n",
    "            return next_btn[0].click() \n",
    "        except ElementClickInterceptedException:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    def parse_names():\n",
    "        if count <=pages:\n",
    "            print(f\"@ page - {count+1}\")\n",
    "            for row in table[index:]:\n",
    "                if row.text is not None:\n",
    "                    name = row.text.split(' ')[-1]\n",
    "                    if '@' in name:\n",
    "                        names.append(name.lstrip('(').rstrip(')'))\n",
    "    \n",
    "    next_page()\n",
    "    sleep(15)\n",
    "                \n",
    "    \n",
    "    if count == 0:\n",
    "        \n",
    "        # get the element of the pop-up modal form\n",
    "        form = driver.find_element_by_id('frm-showShowMoreMarketoForm-mktoForm-mktoForm')\n",
    "        \n",
    "        #send payload to fill the form \n",
    "        name_ele = form.find_element_by_id('frm-showShowMoreMarketoForm-mktoForm-mktoForm-FullName')\n",
    "        name_ele.send_keys(name_) \n",
    "        email_ele = form.find_element_by_id('frm-showShowMoreMarketoForm-mktoForm-mktoForm-Email')\n",
    "        email_ele.send_keys(work_email)\n",
    "        phone_ele = form.find_element_by_id('frm-showShowMoreMarketoForm-mktoForm-mktoForm-Phone')\n",
    "        phone_ele.send_keys(phone)\n",
    "        job_ele = form.find_element_by_id('frm-showShowMoreMarketoForm-mktoForm-mktoForm-Job_Title__c')\n",
    "        job_ele.send_keys(job_title)\n",
    "        company_ele = form.find_element_by_id('frm-showShowMoreMarketoForm-mktoForm-mktoForm-Company')\n",
    "        company_ele.send_keys(company)\n",
    "        company_ele.submit()\n",
    "        \n",
    "        # return to main page and parse table\n",
    "    \n",
    "        table = driver.find_elements_by_class_name('acc-placeholder-img')\n",
    "        count+=1\n",
    "        print(f\"@ page {count+1}\")\n",
    "        for row in table[index:]:\n",
    "            name = row.text.split(' ')[-1]\n",
    "            if '@' in name:\n",
    "                names.append(name.lstrip('(').rstrip(')'))     \n",
    "           \n",
    "        \n",
    "    for i in range(pages):\n",
    "        table = driver.find_elements_by_class_name('acc-placeholder-img') \n",
    "        count+=1\n",
    "        parse_names()\n",
    "        index =len(table)\n",
    "        assert index == len(table),'Not Equal'\n",
    "        next_page()\n",
    "        sleep(15)\n",
    "        \n",
    "        \n",
    "    path = os.getcwd()\n",
    "    return pd.Series(names).drop_duplicates().to_csv(os.path.join(path, \"handles.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ page 1\n",
      "@ page 2\n",
      "@ page - 3\n",
      "@ page - 4\n",
      "@ page - 5\n",
      "@ page - 6\n",
      "@ page - 7\n",
      "@ page - 8\n",
      "@ page - 9\n",
      "@ page - 10\n",
      "@ page - 11\n",
      "@ page - 12\n",
      "@ page - 13\n",
      "@ page - 14\n",
      "@ page - 15\n",
      "@ page - 16\n",
      "@ page - 17\n",
      "@ page - 18\n",
      "@ page - 19\n",
      "@ page - 20\n",
      "@ page - 21\n",
      "@ page - 22\n",
      "@ page - 23\n",
      "@ page - 24\n",
      "@ page - 25\n",
      "@ page - 26\n",
      "@ page - 27\n",
      "@ page - 28\n",
      "@ page - 29\n",
      "@ page - 30\n",
      "@ page - 31\n",
      "@ page - 32\n",
      "@ page - 33\n",
      "@ page - 34\n",
      "@ page - 35\n",
      "@ page - 36\n",
      "@ page - 37\n",
      "@ page - 38\n",
      "@ page - 39\n",
      "@ page - 40\n",
      "@ page - 41\n",
      "@ page - 42\n",
      "@ page - 43\n",
      "@ page - 44\n",
      "@ page - 45\n",
      "@ page - 46\n",
      "@ page - 47\n",
      "@ page - 48\n",
      "@ page - 49\n",
      "@ page - 50\n",
      "@ page - 51\n"
     ]
    }
   ],
   "source": [
    "get_pages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Tweets popular to certain hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using googlesearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(tags, num, language):\n",
    "    \n",
    "    \"\"\"\n",
    "    tag id a lost of tags to search tweets\n",
    "    num is the number of tweets to search for in a tag\n",
    "    language is the language of the tweet to search for\n",
    "    \n",
    "    \"\"\"\n",
    "    tweets = []\n",
    "    for tag in tags:\n",
    "        print('searching google... for '+tag)\n",
    "        tag_url = [url for url in \n",
    "               search(tag+' twitter', stop=num, lang=language, country='Nigeria')][:n]\n",
    "        tweets.extend(tag_url)\n",
    "    print('done searching', '\\ncollecting tweets only')\n",
    "    for idx, i in enumerate(urls):\n",
    "        if 'hashtag' in i:\n",
    "            tweets.pop(idx)\n",
    "    print('done') \n",
    "    return pd.Series(tweets).to_csv(os.path.join(path, \"tweets.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "5    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([1,2,3,4,4,5,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter_influencer_k_means",
   "language": "python",
   "name": "twitter_influencer_k_means"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
